{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning (ML) requires a systematic approach to understanding the data and models used to make predictions. There are a large number of variables that can change the behavior and outcome of an ML model.  The choice the data scientist makes for these variables can mean the difference between the success and failure of the model. Most often, the choices made in one situation cannot be carried over to a new model or experiment. Each new variable requires revisiting the decision of an algorithm and all the parameters associated with it. It is not possible to provide a \"best choice\" for a given task without more experimenting.   \n",
    "\n",
    "The Cortex Python SDK tracks the choices the data scientist makes to improve the performance of the ML model and facilitates support of ML tasks through experiments. An `experiment` is a container for `runs`. `runs` are associated parameters, metrics, and artifacts created in the process of identifying the best algorithms for modeling a skill.\n",
    "\n",
    "Please install `cortex-python`,`cortex-python[builders]` for builder functionality, `cortex-python[viz]` for vizualizations. \n",
    "\n",
    "## Create an Experiment\n",
    "\n",
    "Experiments are created using the Cortex Client:"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**NOTE**: This example requires `cortex-python`, `pandas`, and `scikit-learn` to be installed in your environment, for example:\n",
    "> `pip install cortex-python[jupyter] pandas scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cortex import Cortex\n",
    "\n",
    "client = Cortex.local()\n",
    "exp = client.experiment('example/sample-experiment')\n",
    "exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing the preceeding cell displays the experiment's `runs` as a table. The __ID__ is generated by the `run` and is a [cuid](https://github.com/ericelliott/cuid).  The __Date__ is the time for the `run` the down to the second, formatted in GMT time. Each experiment `run` is timed and the __Took__ column displays the experiment run elpase time. __Params__ and __Metrics__ are keyword arguments that you can use to configure a `run`. The empty table is populated as we create and execute `run`s.\n",
    "\n",
    "### Experiments depend on data\n",
    "\n",
    "Experiments run on datasets. This example uses the [UCI Iris dataset](https://archive.ics.uci.edu/ml/datasets/Iris)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/iris.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a training set and a test set from this data source. Use the sklearn facility to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "all_inputs = df[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']].values\n",
    "all_classes = df['Class'].values\n",
    "\n",
    "(train_inputs, test_inputs, train_classes, test_classes) = train_test_split(all_inputs, all_classes, test_size=0.333, train_size=0.667)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Runs\n",
    "\n",
    "In this example, two runs are created for this experiment using a [decision tree classifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html). The first uses [gini impurity](https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity) as a loss funtion: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc_g = DecisionTreeClassifier(criterion='gini')\n",
    "\n",
    "dtc_g_run = exp.start_run()\n",
    "\n",
    "dtc_g_run.start()\n",
    "dtc_g.fit(train_inputs, train_classes)\n",
    "dtc_g_run.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a second experiment using [information gain](https://en.wikipedia.org/wiki/Information_gain_in_decision_trees) (specified by the parameter `entropy`) for the loss function. Here the `run` context manager is used (which manages the start and stop of a run), making the code more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_e = DecisionTreeClassifier(criterion='entropy')\n",
    "\n",
    "with exp.start_run() as run:\n",
    "    dtc_e.fit(train_inputs, train_classes)\n",
    "\n",
    "dtc_e_run = run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Logging\n",
    "\n",
    "Runs have parameters, metrics, metadata, and artifacts that can be used to track and manage experiment results.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_g_run.set_meta('model','DecisionTreeClassifier')\n",
    "dtc_g_run.log_param('criterion','gini')\n",
    "dtc_g_run.log_artifact('model',dtc_g)\n",
    "dtc_g_run.log_metric('score',dtc_g.score(test_inputs, test_classes))\n",
    "exp.save_run(dtc_g_run)\n",
    "\n",
    "dtc_e_run.set_meta('model','DecisionTreeClassifier')\n",
    "dtc_e_run.log_param('criterion','entropy')\n",
    "dtc_e_run.log_artifact('model',dtc_e)\n",
    "dtc_e_run.log_metric('score',dtc_e.score(test_inputs, test_classes))\n",
    "exp.save_run(dtc_e_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The runs can also be examined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_g_run.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
