{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Is a Dataset?\n",
    "\n",
    "A dataset is a collection of data points with a common schema. The Cortex Python SDK's provides transformations and visualizations to facilitate data cleaning, feature identification and feature construction. In this notebook we demonstrate how to build a dataset and how to view the contents of datasets. Please install `cortex-python`,`cortex-python[builders]` for builder functionality, `cortex-python[viz]` for vizualizations. This example will additionally require `numpy`, which is not installed via `cortex-python`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cortex-python[builders,viz]\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How is a Dataset Built? \n",
    "First, import the Cortex library and instantiate a builder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cortex import Cortex\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "builder = Cortex.local().builder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Builder is the top level factory object in the Cortext Python SDK. The builder returns a factory object that is customized to handle the context for the particular class it builds. A dataset requires a collection of data to be useful, so the factory object returns a dataset builder that can take data in a number of different forms.\n",
    "\n",
    "For example, you can associate a CSV file with a dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data_set_builder = builder.dataset('ds01')\n",
    "\n",
    "csv_example_data_set = csv_data_set_builder.from_csv('./data/sample.csv').build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or a dataset with JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data_set_builder = builder.dataset('ds02')\n",
    "\n",
    "json_example_data_set = json_data_set_builder.from_json('./data/sample.json').build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or from a pandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two columns of random numbers, indexed a through e\n",
    "s = pd.Series(np.random.randn(5), index=['a', 'b', 'c', 'd', 'e'])\n",
    "q = pd.Series(np.random.randn(5), index=['a', 'b', 'c', 'd', 'e'])\n",
    "\n",
    "# make a data frame by composing the columns together and labeling them\n",
    "pdf = pd.DataFrame({'c1':s,'c2':q})\n",
    "\n",
    "pd_data_set_builder = builder.dataset('ds03')\n",
    "\n",
    "data_frame_data_set = pd_data_set_builder.from_df(pdf).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also set the title and description of your dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_example_data_set.title = 'A Title for the example'\n",
    "csv_example_data_set.description = 'A somewhat longer piece of text that describes the purpose of the dataset.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once constructed, the dataset can be explicitly persisted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_example_data_set.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that with the `Cortex.local()` client, the dataset is persisted to the local disk. When using the Cortex client `Cortex.client()`, the dataset is persisted in Cortex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Feature Construction\n",
    "\n",
    "Datasets help in feature construction through the use of pipelines. Pipelines allow functions to be chained together to modify and combine columns to create and clarify new features in the dataset. To find out how to create and persist pipelines, see [Pipeline](https://docs.cortex.insights.ai/docs/cortex-python-sdk-guide/pipeline/).\n",
    "\n",
    "## View Datasets\n",
    "\n",
    "Datasets can be viewed in tables or through visualizations. \n",
    "\n",
    "### Data Dictionary\n",
    "A Dataset can generate a data dictionary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandas DataFrame\n",
    "\n",
    "Datasets can also generate pandas DataFrames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jdf = json_example_data_set.as_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas' DataFrames include several different methods for [viewing data](https://pandas.pydata.org/pandas-docs/stable/10min.html#viewing-data) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jdf.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Visualizations \n",
    "\n",
    "Here are the built-in visualizations that you get with datasets. Visualizations require a dataframe. Most commonly the dataframe is constructed by running a pipeline on the data set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_csv_pl = csv_example_data_set.pipeline('clean_csv_pl')\n",
    "\n",
    "def drop_unused(pipeline, df):\n",
    "    df.drop(columns=['b','c'],inplace=True)\n",
    "\n",
    "clean_csv_pl.add_step(drop_unused)\n",
    "cleaned_csv_df = clean_csv_pl.run(csv_example_data_set.as_pandas())\n",
    "cleaned_csv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = csv_example_data_set.visuals(cleaned_csv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.show_corr_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.show_corr('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.show_corr_pairs('e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.show_dist('e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.show_probplot('e')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
