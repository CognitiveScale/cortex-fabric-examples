{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Pipeline Example\n",
    "\n",
    "This notebook shows how to use basic functions of the Cortex Python SDK pipeline. \n",
    "In this example, see how to modify or enrich datasets to make them suitable for training or modeling. \n",
    "Data is modified in a sequential series of steps. Please install `cortex-python`,`cortex-python[builders]` for builder functionality, `cortex-python[viz]` for vizualizations. "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**NOTE**: This example requires `cortex-python`and `pandas` to be installed in your environment, for example:\n",
    "> `pip install cortex-python[builders] pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Cortex and other required libraries\n",
    "import math\n",
    "from cortex import Cortex\n",
    "\n",
    "# Create a Builder instance\n",
    "cortex = Cortex.local()\n",
    "builder = cortex.builder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, create a data set and populate it from a comma separated values file. A pipeline operates on a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = builder.dataset('example/forest_fires').title('Forest Fire Data')\\\n",
    "    .from_csv('./data/ff.sample.csv').build()\n",
    "# Create a pandas DataFrame to view the last few lines of the dataset\n",
    "data_frame = data_set.as_pandas()\n",
    "data_frame.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataset can have one or more named pipelines. Each pipeline is a chain of Python functions that transform the dataset.  In the next step, create a pipeline named \"prep\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = data_set.pipeline('prep') # create or retrieve the pipline named 'prep'\n",
    "pipeline.reset() # removes any previous steps or context for this pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One pipeline step can be used to add a new column.\n",
    "\n",
    "This [dataset](http://piano.dsi.uminho.pt/~pcortez/fires.pdf) uses components from the Fire Weather Index to make predictions. One element, the Build Up Index (BUI) is based on a relation of two other columns and is omitted. This step adds that missing element. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bui(pipeline, df):\n",
    "    df['BUI'] = (0.8 * df['DMC'] * df['DC'])/(df['DMC'] + 0.4 * df['DC'])\n",
    "\n",
    "pipeline.add_step(add_bui)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the preceeding code, the pipeline step functions require a pipeline and a dataframe parameter. The [pandas DataFrame](https://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe) provides a rich set of functions for operating on table data.\n",
    "\n",
    "A pipeline step may be used to modify a column.\n",
    "\n",
    "The dataset's documentation says that the last column, __area__, is skewed towards zero and should be adjusted logarithmically \"to improve regression results for right-skewed targets\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_area(pipeline, df):\n",
    "    df['area'] = df['area'].map(lambda a: math.log1p(a))\n",
    "    \n",
    "pipeline.add_step(fix_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Pipeline\n",
    "After all the steps are added, you can call `run` on the pipeline. This invokes each of the steps in order and returns a transformed DataFrame instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.run(data_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
