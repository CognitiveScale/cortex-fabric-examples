{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Basic setup and sanity checking\n",
    "%run ./00_setup.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action Authoring and Deployment\n",
    "A Cortex Action can be authored and deployed from within a notebook for rapid prototyping and testing.  The Cortex SDK for Python includes an iPython Magic called `%%cortex_action` that takes a notebook cell and deploys it as a Cortex Action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%cortex_action --name c12e/image-classify --function classify --requirements watson_developer_cloud\n",
    "\n",
    "from cortex import Message\n",
    "from cortex import Cortex\n",
    "from watson_developer_cloud import VisualRecognitionV3\n",
    "\n",
    "def classify(params):\n",
    "\n",
    "    msg = Message(params)\n",
    "    client = Cortex.client(api_endpoint=msg.apiEndpoint, token=msg.token)\n",
    "    image_url = msg.payload.get('imageUrl')\n",
    "    apiKey = msg.payload.get('apiKey')\n",
    "    classifierId = msg.payload.get('classifierId')\n",
    "\n",
    "    if classifierId is None or classifierId == \"\":\n",
    "        return {\"payload\": \"Classifier ID Not Provided\"}\n",
    "\n",
    "    visual_recognition = VisualRecognitionV3('2018-03-19', iam_apikey=apiKey)\n",
    "\n",
    "    response = visual_recognition.classify(url=image_url, classifier_ids=[classifierId], threshold=\"0.5\").get_result()\n",
    "\n",
    "    if response is not None:\n",
    "        return {\"payload\": response}\n",
    "    else:\n",
    "        return {\"payload\": \"Unable to get response from Watson Visual Recognition\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Testing\n",
    "Once the Action is built, we can run both a local and remote test.  The local test in our example can be done by simply calling the `detect` function we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def test_detect(args):\n",
    "    imageUrl = 'https://showmecables-static.scdn3.secure.raxcdn.com/media/catalog/product/cache/c687aa7517cf01e65c009f6943c2b1e9/u/s/usb-a-male-to-usb-b-female-adapter-3506-1.jpg'\n",
    "    classifierId = 'Connectors_227384960'\n",
    "    apiKey = 'BVaceevn9oDep6ow12MASoLubdwkLYkDYEKdjLdBKFRi'\n",
    "    m = Message.with_payload({'imageUrl': imageUrl,'apiKey':apiKey,'classifierId':classifierId})\n",
    "    result = classify(m.to_params())\n",
    "    pprint(result['payload'])\n",
    "\n",
    "test_detect(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remote Testing\n",
    "Using the Cortex client, we can execute a remote test of our Action to make sure it deployed as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Cortex.client()\n",
    "action = client.action('c12e/image-classify')\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageUrl = 'https://showmecables-static.scdn3.secure.raxcdn.com/media/catalog/product/cache/c687aa7517cf01e65c009f6943c2b1e9/u/s/usb-a-male-to-usb-b-female-adapter-3506-1.jpg'\n",
    "classifierId = 'Connectors_227384960'\n",
    "apiKey = 'BVaceevn9oDep6ow12MASoLubdwkLYkDYEKdjLdBKFRi'\n",
    "params = {'payload': {'imageUrl': imageUrl,'apiKey':apiKey,'classifierId':classifierId}}\n",
    "rs = action.invoke(client.message(params.get('payload')))\n",
    "result = rs.payload\n",
    "classifiers =  result.get(\"images\")\n",
    "print (classifiers[0].get('classifiers'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
