{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ames Housing Prices - Step 5: Model Deployment\n",
    "Now that we have trained and selected our optimal model, its time to deploy it.  This notebook demonstrates how to user our Experiment and Pipelines from the previous steps to easly deploy our model as a Cortex Action. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic setup\n",
    "%run config.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Cortex 5 and create a Builder instance\n",
    "cortex = Cortex.client()\n",
    "\n",
    "# Running locally isn't meaningful for the deploy step, since this deploys to the Cortex client.\n",
    "builder = cortex.builder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Experiment\n",
    "Let's load our experiment from the previous step and find the model we want to deploy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = cortex.experiment('kaggle/ames-housing-regression')\n",
    "exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The model created in the last run looks to be the best, let's deploy it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = exp.runs()[-1]\n",
    "model = run.get_artifact('model')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model deployment - Step 1: Configure Data Pipeline for Inputs\n",
    "Our model was trained with data that has had cleaning and feature engineering steps applied to it.  Since we want our users to send us the actual raw data, we need to deploy our pipeline to transform the input data into the form we expect.  This requires applying some of the same steps from before, but also requires us to remember some of the data created during model training such as the median values of certain columns and the final list of _dummy_ categorical columns created during feature engineering.  Luckily, our pipelines have a memory in the form of _context_ that we can reference here to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = cortex.dataset('kaggle/ames-housing-train')\n",
    "\n",
    "# Model our feature pipeline after the 'clean' pipeline\n",
    "x_pipe = builder.pipeline('x_pipe')\n",
    "x_pipe.from_pipeline(train_ds.pipeline('clean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same idea from our training prep, however we need to use the median values we computed before which we stored in our pipeline context\n",
    "def fill_median_cols_ctx(pipeline, df):\n",
    "    fill_median_cols = ['GarageArea','TotalBsmtSF', 'MasVnrArea', 'BsmtFinSF1', 'LotFrontage', 'BsmtUnfSF', 'GarageYrBlt']\n",
    "    [df[j].fillna(pipeline.get_context('{}_median'.format(j)), inplace=True) for j in fill_median_cols]\n",
    "                  \n",
    "# The dummy column conversion we did during training needs to be applied here.  Afterwards there will be missing columns because \n",
    "# our input instance will only contain at most one value per category.  We need to fill in the other expected columns.  We stored\n",
    "# the expected set of columns in our pipeline so we can easily do this now.\n",
    "def fix_columns(pipeline, df):\n",
    "    all_cols = pipeline.get_context('columns')\n",
    "    missing_cols = set(all_cols) - set(df.columns)\n",
    "    for c in missing_cols:\n",
    "        df[c] = 0\n",
    "    \n",
    "    # make sure we have all the columns we need\n",
    "    assert(set(all_cols) - set(df.columns) == set())\n",
    "    \n",
    "    return df[all_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The feature engineering pipeline contains the complete list of dummy columns in addition to some steps we need\n",
    "engineer_pipe = train_ds.pipeline('engineer')\n",
    "x_pipe.set_context('columns', engineer_pipe.get_context('columns'))\n",
    "\n",
    "# Reuse steps from our clean, features, and engineer pipelines\n",
    "fill_zero_cols = x_pipe.get_step('fill_zero_cols')\n",
    "fill_na_none = x_pipe.get_step('fill_na_none')\n",
    "get_dummies = engineer_pipe.get_step('get_dummies')\n",
    "print(engineer_pipe.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build our final input pipeline\n",
    "x_pipe.reset()\n",
    "x_pipe.add_step(fill_zero_cols)\n",
    "x_pipe.add_step(fill_median_cols_ctx)\n",
    "x_pipe.add_step(fill_na_none)\n",
    "x_pipe.add_step(get_dummies)\n",
    "x_pipe.add_step(fix_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model deployment - Step 2: Configure Data Pipeline for Output\n",
    "If you remember, we scaled our target variable using the numpy _log1p_ function.  We need to inverse this using the _exp_ function so our predicted value is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pipe = builder.pipeline('y_pipe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_target(pipeline, df):\n",
    "    df['SalePrice'] = np.exp(df['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pipe.add_step(rescale_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model deployment - Step 3: Build and Deploy Cortex Action\n",
    "##### when using Python 3.6 - Use Base Image 'c12e/cortex-python36:29c5a9c' when building actions.\n",
    "##### when using Python 3.7 - Use Base Image 'c12e/cortex-python37:29c5a9c' when building actions.\n",
    "\n",
    "Now that we have our input and output pipelines, we can use the Cortex Builder to package and deploy our model in one step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.action('kaggle/ames-housing-predict')\\\n",
    "    .with_requirements(['scikit-learn>=0.20.0,<1'])\\\n",
    "    .from_model(model, x_pipeline=x_pipe, y_pipeline=y_pipe, target='SalePrice')\\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = cortex.action('kaggle/ames-housing-predict')\n",
    "action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "---\n",
    "Unit test for the Action.  Make sure our action is ready for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "params = {\n",
    "    \"columns\": ['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC', 'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType', 'SaleCondition'],\n",
    "    \"values\": [[20,\"RH\",80.0,11622,\"Pave\",None,\"Reg\",\"Lvl\",\"AllPub\",\"Inside\",\"Gtl\",\"NAmes\",\"Feedr\",\"Norm\",\"1Fam\",\"1Story\",5,6,1961,1961,\"Gable\",\"CompShg\",\"VinylSd\",\"VinylSd\",\"None\",0.0,\"TA\",\"TA\",\"CBlock\",\"TA\",\"TA\",\"No\",\"Rec\",468.0,\"LwQ\",144.0,270.0,882.0,\"GasA\",\"TA\",\"Y\",\"SBrkr\",896,0,0,896,0.0,0.0,1,0,2,1,\"TA\",5,\"Typ\",0,None,\"Attchd\",1961.0,\"Unf\",1.0,730.0,\"TA\",\"TA\",\"Y\",140,0,0,0,120,0,None,\"MnPrv\",None,0,6,2010,\"WD\",\"Normal\"]]\n",
    "}\n",
    "\n",
    "result = action.invoke(message=cortex.message(params))\n",
    "print(result.payload)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Cortex Skill\n",
    "Now that our Action is ready and tested, we can move on to building a Cortex Skill.  We start by creating a Schema that defines our input for Ames Housing price prediction.  The schema will be built automatically using the parameters we already defined in our training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_schema = builder.schema('kaggle/ames-housing-instance').title('Ames Housing Test Instance').from_parameters(train_ds.parameters[1:][:-1]).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _builder_ has multiple entry points, we use the _skill_ method here to declare a new \"Ames Housing Price Prediction\" Skill.  Each _builder_ method returns an instance of the builder so we can chain calls together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = builder.skill('kaggle/ames-housing-price-predict').title('Ames Housing Price Prediction').description('Predicts the price of a houses in Ames, Iowa.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the Input sub-builder to construct our Skill Input.  This is where we declare how our Input will route messages.  In this simple case, we use the _all_ routing which routes all input messages to same Action for processing and declares wich Output to route Action outputs to.  We pass in our Action that we built previously to wire the Skill to the Action (we could have also passed in the Action name here).  Calling _build_ on the Input will create the input object, add it to the Skill builder, and return the Skill builder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b.input('ames-house').title('Ames House').use_schema(x_schema.name).all_routing(action, 'price-prediction').build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous step, we referenced an Output called **price-prediction**.  We can create that Output here using the Output sub-builder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b.output('price-prediction').title('Price Prediction').parameter(name='SalePrice', type='number', format='double').build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can preview the CAMEL document our builder will create to make sure everything looks correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.to_camel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Build and Publish the Skill to the Marketplace\n",
    "This will build the Skill and publish it to my private marketplace.  It will then be available for use in the Agent Builder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill = b.build()\n",
    "print('%s (%s) v%d' % (skill.title, skill.name, skill.version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
