{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo Notebook that uses FLAML framework's AutoML feature for task oriented ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Use Case\n",
    "\n",
    "This model will leverage historical service request data and relevant details to predict the time required for fulfilling new service requests for a Telecom customer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 : Install FLAML Library for AutoML and Update Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** NOTE : Install libomp using `brew install libomp` to run this and install Flaml-AutoML on M1 Mac."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install flaml\n",
    "%pip install --upgrade pandas \"dask[complete]\"\n",
    "%pip install \"flaml[automl]\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2. Load the dataset and create training and test datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "try:\n",
    "    data = pd.read_csv('../datasets/pro_MTNNSR_v3.csv')\n",
    "\n",
    "    y = data['Request_Closing_Time_in_Seconds_CLM']\n",
    "    x = data.drop('Request_Closing_Time_in_Seconds_CLM',axis=1)\n",
    "\n",
    "    X_train,X_test,y_train,y_test = train_test_split(x,y,test_size = 0.3)\n",
    "except (ServerError, Exception):\n",
    "    from sklearn.datasets import make_classification\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from pandas import DataFrame\n",
    "\n",
    "    X, y = make_classification(n_samples=539383, n_features=10)\n",
    "    X = DataFrame(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Run FLAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' import AutoML class from flaml package '''\n",
    "from flaml import AutoML\n",
    "automl = AutoML()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    \"time_budget\": 600,  # total running time in seconds\n",
    "    \"metric\": 'r2', \n",
    "                        # check the documentation for options of metrics (https://microsoft.github.io/FLAML/docs/Use-Cases/Task-Oriented-AutoML#optimization-metric)\n",
    "    \"task\": 'regression',  # task type\n",
    "    \"log_file_name\": 'isr-experiment.log',  # flaml log file\n",
    "    \"seed\": 7654321,    # random seed\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl.fit(X_train=X_train, y_train=y_train, **settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''retrieve best config and best learner'''\n",
    "print('Best ML leaner:', automl.best_estimator)\n",
    "print('Best hyperparmeter config:', automl.best_config)\n",
    "print('Best accuracy on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
    "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl.model.estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''pickle and save the automl object'''\n",
    "import pickle\n",
    "with open('isr-automl.pkl', 'wb') as f:\n",
    "    pickle.dump(automl, f, pickle.HIGHEST_PROTOCOL)\n",
    "'''load pickled automl object'''\n",
    "with open('isr-automl.pkl', 'rb') as f:\n",
    "    automl = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''compute predictions of testing dataset''' \n",
    "y_pred = automl.predict(x_test)\n",
    "print('Predicted labels', y_pred)\n",
    "print('True labels', y_test)\n",
    "y_pred_1 = automl.predict(x_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' compute different metric values on testing dataset'''\n",
    "from flaml.ml import sklearn_metric_loss_score\n",
    "from sklearn.metrics import mean_absolute_error,r2_score\n",
    "print('R2', '=', 1 - sklearn_metric_loss_score('r2', y_pred, y_test))\n",
    "print('mae', '=', sklearn_metric_loss_score('mae',y_test,y_pred))\n",
    "print('rmse', '=', sklearn_metric_loss_score('rmse', y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml.ml import sklearn_metric_loss_score\n",
    "print('train rmse', '=', sklearn_metric_loss_score('rmse', automl.predict(x_train), y_train))\n",
    "print(' test rmse', '=', sklearn_metric_loss_score('rmse', automl.predict(x_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml.automl.data import get_output_from_log\n",
    "time_history, best_valid_loss_history, valid_loss_history, config_history, metric_history = \\\n",
    "    get_output_from_log(filename=settings['log_file_name'], time_budget=240)\n",
    "for config in config_history:\n",
    "    print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Wall Clock Time (s)')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.scatter(time_history, 1 - np.array(valid_loss_history))\n",
    "plt.step(time_history, 1 - np.array(best_valid_loss_history), where='post')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def plot_prediction(train_data = X_train,\n",
    "                  train_labels = y_train,\n",
    "                    test_data = X_test,\n",
    "                    test_labels = y_test,\n",
    "                      predictions = None):\n",
    "  plt.figure(figsize=(10, 7))\n",
    "  train_data=np.arange(0,len(train_data),1) \n",
    "\n",
    "  plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training Data!\")\n",
    "  test_data=np.arange(0,len(test_data),1)\n",
    "  plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing Data\")\n",
    "\n",
    "  if predictions is not None:\n",
    "    plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions!!!\")\n",
    "\n",
    "  plt.legend(prop={\"size\":14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction(predictions=y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
