{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection With Pipelines\n",
    "\n",
    "This notebook is a template for common feature selection activities. There are a large number of [feature selection techniques](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection). This template uses three techniques. Although you may want to use other techniques, it's beneficial to use a feature selection pipeline to select a subset of the features. This is because it's likely that you'll go through the process of build models, getting feedback and making adjustments to your data several times.  Keeping track of what transformation you made in previous iterations can help you better refine your model.  \n",
    "\n",
    "## Setup\n",
    "\n",
    "This section defines variables used in the following sections to construct and run the pipeline. You can change the values of the variables to meet your needs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = './data/feature.csv'\n",
    "name_space = 'example'\n",
    "dataset_name = 'sample02'\n",
    "full_ds_name = '/'.join([name_space, dataset_name])\n",
    "ds_pred_trgt_name = 'CATEGORY' \n",
    "rfe_feat_ct = 4 \n",
    "vtr_threshold = 0.16 # = 0.8*(1-0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "Import the pandas' or other needed libraries, and then create a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cortex import Cortex\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "data_frame = pd.read_csv(data_file)\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next line a local Cortex client is created. You create a server-side client by replacing `Cortex.local()` with `Cortex.client()`. Doing that will cause the data set to be persisted in Cortex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cortex = Cortex.local()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make a dataset, using the cortex builder. The dataset is used to create the pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = cortex.builder()\n",
    "data_set_builder = builder.dataset(full_ds_name)\n",
    "feat_sel_dataset = data_set_builder.from_csv(data_file).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A namespace is an organizational element for data saved in the Cortex infrastructure. Use it to keep various artifacts related to a particular project together. This template combines the namespace and the dataset name to create a qualified dataset name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_name = 'feat_sel'\n",
    "full_pipeline_name = '/'.join([name_space, pipeline_name])\n",
    "\n",
    "feat_sel_dataset = cortex.dataset(full_ds_name) \n",
    "pipeline = feat_sel_dataset.pipeline(full_pipeline_name)\n",
    "pipeline.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can select from the following techniques to create a qualified data set. Adding the feature engineering techniques to the pipeline in the order you want them run provides a well defined, reproducible method of curating the data for improving the predictability of the model. \n",
    "\n",
    "## Feature Construction\n",
    "\n",
    "Feature construction can be used to add a new feature to that data that is some function of existing features. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_theta(pipeline, df):\n",
    "    df['THETA'] = df['ETA'] * df['ZETA']\n",
    "    return df\n",
    "    \n",
    "pipeline.add_step(calc_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Recursive Feature Elimination\n",
    "\n",
    "Recursive feature elimination (RFE) uses a model (in this case a [Support Vector Regression](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html) model) to repeatedly fit the data to the target, using different combinations of features. Features that contribute the least to the prediction are eliminated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rfe(pipeline, df):\n",
    "    cols = list(df.columns)\n",
    "    y = df[ds_pred_trgt_name].values \n",
    "    estmtr =  SVR(kernel='linear')\n",
    "    rfe = RFE(estmtr, rfe_feat_ct)\n",
    "    rfe = rfe.fit(df, y)\n",
    "    temp = pd.Series(rfe.support_, index = cols)\n",
    "    selected_features_rfe = temp[temp==True].index\n",
    "    return df[selected_features_rfe]\n",
    "    \n",
    "pipeline.add_step(calc_rfe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance Threshold Reduction\n",
    "\n",
    "Features that have a low variance (in other words, that tend to have very similar values) across records may also not contribute much to a model's predictive ability. Eliminating such features decreases model training time.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_vtr(pipeline, df):\n",
    "    cols = list(df.columns)\n",
    "    sel = VarianceThreshold(threshold=vtr_threshold)\n",
    "    sel.fit_transform(df)\n",
    "    temp = pd.Series(sel.get_support(), index = cols)\n",
    "    selected_features_vtr = temp[temp==True].index\n",
    "    return df[selected_features_vtr]\n",
    "    \n",
    "pipeline.add_step(calc_vtr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_sel_ds = pipeline.run(data_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_sel_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
